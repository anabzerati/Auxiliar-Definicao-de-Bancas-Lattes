A tecnologia é historicamente uma área de estudos inacessível ao grande público, com essa inacessibilidade se estendendo até tecnologias de aprendizado de máquina e de processamento de linguagem natural modernas. Existe uma crescente necessidade de desenvolvimento de aplicações que sejam acessíveis e eficazes de tais tecnologias, capazes de obter resultados satisfatórios com custos acessíveis para o pesquisador comum. Este trabalho propõe o treinamento e avaliação de diferentes modelos de linguagem, sendo dentre as várias abordagens possíveis estudados principalmente dois tipos de modelos: Transformer e xLSTM. Os dados foram obtidos da Wikipedia e outras fontes na internet, pré-processados a fim de reduzir recursos computacionais exigidos e otimizar a tarefa. O objetivo deste trabalho é treinar e avaliar os modelos de linguagem de escolha, utilizando a métrica de perplexidade e testes auto-regressivos para o fim de medir a coerência e a capacidade preditiva. Os resultados obtidos explicitam as dificuldades acerca de estudos sobre a área, sendo o modelo de melhor performance o GPT-2 pré-treinado com a adição de ajustes finos.